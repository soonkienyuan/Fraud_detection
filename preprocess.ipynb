{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimension Reduction of correlated features group via PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_feature_subset = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipeLine:\n",
    "    def __init__(self, steps = None) -> None:\n",
    "        self.steps = [] if steps is None else steps\n",
    "        \n",
    "    def add_step(self, f, *args, **kwargs):\n",
    "        self.steps.append((f, args, kwargs))\n",
    "    \n",
    "    def run_all(self, df):\n",
    "        for step, args, kwargs in self.steps:\n",
    "            df = step(df, *args, **kwargs)\n",
    "        return df\n",
    "preprocess_pipes = PipeLine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def pca_reduce_fit_transform(df, cols, nm):\n",
    "    non_na_mask = df[cols].isna().all(axis=1)\n",
    "    non_na_idx = non_na_mask[~non_na_mask].index\n",
    "\n",
    "    pca = PCA(1).fit(df[cols].dropna())\n",
    "    df.loc[non_na_idx, nm] = pca.transform(df.loc[non_na_idx, cols])\n",
    "    \n",
    "    return df, pca\n",
    "\n",
    "def pca_reduce_fit(df, cols):\n",
    "    non_na_mask = df[cols].isna().all(axis=1)\n",
    "    non_na_idx = non_na_mask[~non_na_mask].index\n",
    "\n",
    "    pca = PCA(1).fit(df[cols].dropna())\n",
    "    \n",
    "    return pca\n",
    "\n",
    "def pca_reduce_transform(df, pca, nm):\n",
    "    cols = pca.feature_names_in_\n",
    "    non_na_mask = df[cols].isna().all(axis=1)\n",
    "    non_na_idx = non_na_mask[~non_na_mask].index\n",
    "    \n",
    "    df.loc[non_na_idx, nm] = pca.transform(df.loc[non_na_idx, cols])\n",
    "    \n",
    "    return df, pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "red_grps = {}\n",
    "\n",
    "for p, grps in enumerate(vesta_subset_pages[:2]):\n",
    "    for cols in grps:\n",
    "        c_it = count()\n",
    "        if len(cols) <= 2:\n",
    "            continue\n",
    "        nm = f'PCA_{p}_{next(c_it)}'\n",
    "        transaction_df, pca = pca_reduce_transform(transaction_df, cols, nm)\n",
    "        red_grps[nm] = pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:len(pca.feature_names_in_) for k, pca in red_grps.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['PCA_7_0'] + list(red_grps['PCA_7_0'].feature_names_in_)\n",
    "cor = transaction_df[cols].corr()\n",
    "sns.heatmap(cor,cmap='Blues');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2324a66782fee6ab9f0bdb3c9e79ee636ed86487484f245c4444858429ce7730"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
