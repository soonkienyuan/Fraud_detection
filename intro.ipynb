{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "To make real progress along the path toward becoming an expert in the data mining field, it is helpful to apply all your data mining knowledge to a project task. This project will require you to explore the actual data, gain experience implementing data mining projects and become industry-ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instruction\n",
    "- browse the internet for the topics covered in the data mining field and choose ONE topic that best suits your group.\n",
    "- discuss with your colleagues the problems/ issues to solve and select the MESSY/ NOISE data (may extract several datasets) from established sources from websites such as GitHub, Kaggle, UCI repository, etc. The dataset must be reflected/contribute to the real-world problem you will solve. Each group should have different problems to solve.\n",
    "- utilise python or any analytics tools to develop data mining models and solve the problem. Additional tools to be used are recommended.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements\n",
    "The project requires all the followings:\n",
    "1. **Executive Summary**\n",
    "   \n",
    "    Description of the selected project, problem to be solved, and basic description of the data set from the sources.\n",
    "\n",
    "2. **Summary of the Project Context and Objectives**\n",
    "   \n",
    "    Summarise your project context and list the objectives covered in your project.\n",
    "\n",
    "3. **Methodology**\n",
    "\n",
    "    Create a data pipeline to depict your sequence of actions that move data from a source to a destination. Show and explain all phases or steps involved in the data mining process, including the data preprocessing (ETL/ ELT), modelling, evaluation and deployment in your project development.\n",
    "\n",
    "4. **Results and Discussion**\n",
    "\n",
    "    Produce and explain all codes, GUI, graphs, diagrams, or any visualisation output from the project development.\n",
    "\n",
    "5. **Conclusion**\n",
    "\n",
    "    Conclude your project and discuss some contributions to society, the environment, systems, etc.\n",
    "\n",
    "6. **References**\n",
    "\n",
    "    Cite every single reference used in completing the project. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Description\n",
    "\n",
    "In this competition you are predicting the probability that an online transaction is fraudulent, as denoted by the binary target isFraud. \n",
    "For each TransactionID in the test set, you must predict a probability for the isFraud variable.\n",
    "\n",
    "The data is broken into two files identity and transaction, which are joined by TransactionID. Not all transactions have corresponding identity information.\n",
    "\n",
    "1. [Further Information and related discussion](https://www.kaggle.com/c/ieee-fraud-detection/discussion/101203)\n",
    "2. [Kaggler's insight](https://www.kaggle.com/c/ieee-fraud-detection/discussion/101203#610146)\n",
    "3. [Labelling logic](https://www.kaggle.com/c/ieee-fraud-detection/discussion/101203#589276)\n",
    "\n",
    "    It's a good question.\n",
    "\n",
    "    Yes, they're all real data, no synthetic data. The logic of our labeling is define reported chargeback on the card as fraud transaction (isFraud=1) and transactions posterior to it with either user account, email address or billing address directly linked to these attributes as fraud too. If none of above is reported and found beyond 120 days, then we define as legit transaction (isFraud=0).\n",
    "    However, in real world fraudulent activity might not be reported, e.g. cardholder was unaware, or forgot to report in time and beyond the claim period, etc. In such cases, supposed fraud might be labeled as legit, but we never could know of them. Thus, we think they're unusual cases and negligible portion.\n",
    "4. [Main Ideas from Grandmaster's EDA](https://www.kaggle.com/code/cdeotte/eda-for-columns-v-and-id/notebook)\n",
    "\n",
    "Transaction Table *\n",
    "- TransactionDT: timedelta from a given reference datetime (not an actual timestamp)\n",
    "- TransactionAMT: transaction payment amount in USD\n",
    "- ProductCD: product code, the product for each transaction\n",
    "- card1 - card6: payment card information, such as card type, card category, issue bank, country, etc.\n",
    "- addr: address\n",
    "- dist: distance\n",
    "- P_ and (R__) emaildomain: purchaser and recipient email domain\n",
    "- C1-C14: counting, such as how many addresses are found to be associated with the payment card, etc. The actual meaning is masked.\n",
    "- D1-D15: timedelta, such as days between previous transaction, etc.\n",
    "- M1-M9: match, such as names on card and address, etc.\n",
    "- Vxxx: Vesta engineered rich features, including ranking, counting, and other entity relations.\n",
    "\n",
    "Categorical Features:\n",
    "- ProductCD\n",
    "- card1 - card6\n",
    "- addr1, addr2\n",
    "- P_emaildomain\n",
    "- R_emaildomain\n",
    "- M1 - M9\n",
    "\n",
    "Identity Table *\n",
    "\n",
    "Variables in this table are identity information – network connection information (IP, ISP, Proxy, etc) and digital signature (UA/browser/os/version, etc) associated with transactions.\n",
    "They're collected by Vesta’s fraud protection system and digital security partners.\n",
    "(The field names are masked and pairwise dictionary will not be provided for privacy protection and contract agreement)\n",
    "\n",
    "Categorical Features:\n",
    "- DeviceType\n",
    "- DeviceInfo\n",
    "- id_12 - id_38"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.2 (tags/v3.10.2:a58ebcc, Jan 17 2022, 14:12:15) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2324a66782fee6ab9f0bdb3c9e79ee636ed86487484f245c4444858429ce7730"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
